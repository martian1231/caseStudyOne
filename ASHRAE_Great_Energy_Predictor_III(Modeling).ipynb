{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASHRAE_Great_Energy_Predictor_III(Modeling).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fdde3c4ef0cd4d9e985180b377fdbf62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b479f53bc5b5432d8966bb72016cc390",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ddd169612a1f4a6e95f7b06012e5a418",
              "IPY_MODEL_07570602500448b989c61de2c453cad6"
            ]
          }
        },
        "b479f53bc5b5432d8966bb72016cc390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ddd169612a1f4a6e95f7b06012e5a418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_75e912bdb96640cea1cfb56f75ca5281",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 16,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 16,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2be5f13d45944280a5f9bcfcc7180db3"
          }
        },
        "07570602500448b989c61de2c453cad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0e24eb58bcf0461d88021aeb8f19479d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16/16 [4:49:48&lt;00:00, 1086.77s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad6357ab993444f6aa5bd651c04d78a5"
          }
        },
        "75e912bdb96640cea1cfb56f75ca5281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2be5f13d45944280a5f9bcfcc7180db3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e24eb58bcf0461d88021aeb8f19479d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad6357ab993444f6aa5bd651c04d78a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1adb9390397d4222b5baa18aa0c9131e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cbf071b1abad4bd687f802ea7bfad299",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a9888b5091564b3f89c1cd73c9dde07d",
              "IPY_MODEL_fef73b2113fa44ae9d4e9ee6486d7dd4"
            ]
          }
        },
        "cbf071b1abad4bd687f802ea7bfad299": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9888b5091564b3f89c1cd73c9dde07d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3975ada082f94b62804a2304f1114841",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 16,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 16,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d276d0e378304970858f3c37b38e7b8d"
          }
        },
        "fef73b2113fa44ae9d4e9ee6486d7dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e6f1cf1eab7c403888553856bb2d6f9f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16/16 [10:11&lt;00:00, 38.19s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a2d255fcb4842a5adbdd275710306c9"
          }
        },
        "3975ada082f94b62804a2304f1114841": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d276d0e378304970858f3c37b38e7b8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6f1cf1eab7c403888553856bb2d6f9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a2d255fcb4842a5adbdd275710306c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JRnhKVN7yX3z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "outputId": "288926b3-ae73-43b8-8a01-540e1122832a"
      },
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime\n",
        "from prettytable import PrettyTable\n",
        "from catboost import CatBoostRegressor\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import timeit\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import KFold\n",
        "import lightgbm as lgb\n",
        "from tqdm.notebook import tqdm\n",
        "import pickle\n",
        "import datetime\n",
        "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
        "from pandas.api.types import is_categorical_dtype\n",
        "import statsmodels.api as sm\n",
        "from collections import defaultdict\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import warnings\n",
        "from google.colab import drive\n",
        "\n",
        "# get the default figure size\n",
        "sns.set(rc={'figure.figsize':(15,5)})\n",
        "path = './drive/My Drive/data/case_study_1/models/'\n",
        "dir_ = './drive/My Drive/data/case_study_1/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/f9/0626bbdb322e3a078d968e87e3b01341e7890544de891d0cb613641220e6/ipython-autotime-0.1.tar.bz2\n",
            "Building wheels for collected packages: ipython-autotime\n",
            "  Building wheel for ipython-autotime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipython-autotime: filename=ipython_autotime-0.1-cp36-none-any.whl size=1832 sha256=a834d993ac204ca0600eea35f291d1e845f95fde0a7e607b51d32a0a815bf2ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/df/81/2db1e54bc91002cec40334629bc39cfa86dff540b304ebcd6e\n",
            "Successfully built ipython-autotime\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.1\n",
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/6c/6608210b29649267de52001b09e369777ee2a5cfe1c71fa75eba82a4f2dc/catboost-0.24-cp36-none-manylinux1_x86_64.whl (65.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65.9MB 54kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.0.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O1MATsXUydn9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "98e40255-212f-4256-be4d-96acded1d129"
      },
      "source": [
        "def mount():\n",
        "  '''Mount the google drive to current file system'''\n",
        "  drive.mount('/content/drive')\n",
        "def mount():\n",
        "  '''Mount the google drive from current file system'''\n",
        "  drive.flush_and_unmount()\n",
        "mount()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n",
            "time: 1min 10s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HbYoZNO97s-h"
      },
      "source": [
        "# Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VySqeR7S0Oaq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a7578bad-97ac-404b-fea9-310820965155"
      },
      "source": [
        "def save_object(obj, filename):\n",
        "  \"\"\"Save the object into the disk\"\"\"\n",
        "  \n",
        "  dirname = os.path.dirname(filename)\n",
        "  if not os.path.exists(dirname):\n",
        "    os.makedirs(dirname)\n",
        "  \n",
        "  with open(filename, 'wb') as output: \n",
        "    pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def load_object(filename):\n",
        "  \"\"\"Load the object into the disk\"\"\"\n",
        "  with open(filename, 'rb') as output:\n",
        "    return pickle.load(output)\n",
        "\n",
        "def add_time_features(df):\n",
        "    \"\"\"Add date time features by parsing timestamp\"\"\"\n",
        "    # add dayofyear column\n",
        "    df[\"dayofyear\"] = df.timestamp.dt.dayofyear\n",
        "    # add day column\n",
        "    df[\"day\"] = df.timestamp.dt.day\n",
        "    # add week column\n",
        "    df[\"weekday\"] = df.timestamp.dt.weekday\n",
        "    # add hour column\n",
        "    df[\"hour\"] = df.timestamp.dt.hour\n",
        "    # add month column\n",
        "    df[\"month\"] = df.timestamp.dt.month\n",
        "    # add weekend column\n",
        "    df[\"weekend\"] = df.timestamp.dt.weekday.apply(lambda x: 0 if x <5 else 1)\n",
        "\n",
        "def free(obj_list):\n",
        "  '''Remove unwanted objects to save memory'''\n",
        "  # deleted the objects\n",
        "  del obj_list\n",
        "  # call the grabage collector\n",
        "  gc.collect()\n",
        "\n",
        "def merge_all(df, weather_df, building_meta_df):\n",
        "  \"\"\"Merge all data\"\"\"\n",
        "  # merge train and bulding meta data on building id\n",
        "  merged = df.merge(building_meta_df,\n",
        "                    how= \"left\",\n",
        "                    on= [\"building_id\"])\n",
        "  \n",
        "  # merge last merged df with weather data\n",
        "  df_merged = merged.merge(weather_df, how= \"left\",\n",
        "                           on= [\"site_id\", \"timestamp\"])\n",
        "  # clean up\n",
        "  free([df, weather_df, building_meta_df, merged])\n",
        "\n",
        "  return df_merged\n",
        "\n",
        "def interpolate_linear(df, column_list, n_site):\n",
        "  '''Impute missing values using linear interpolation in both direction'''\n",
        "  for i in range(n_site):\n",
        "    # for each column and current site id, impute missing values\n",
        "    for col in column_list:\n",
        "      df.loc[df.site_id == i,  col] = df.loc[df.site_id == i, col].interpolate(method ='linear', limit_direction ='both')\n",
        "\n",
        "def missing_info(df):\n",
        "  \"\"\"Print missing rows and percentage for each feature\"\"\"\n",
        "  # number of null rows\n",
        "  df.isna().sum()\n",
        "\n",
        "  # get the count of nan value rows columnwise\n",
        "  df_null_count = df.isna().sum().reset_index()\n",
        "  df_null_count.rename(columns={\"index\": \"column_name\", 0: \"missing_row_count\"}, inplace= True)\n",
        "  # alter the column name\n",
        "  # compute the percentage and add new percentage column\n",
        "  df_null_count[\"missing_row_percentage\"] = df_null_count.missing_row_count/df.shape[0]\n",
        "  df_null_count\n",
        "\n",
        "# Original code from  https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n",
        "def reduce_mem_usage(df, use_float16=False):\n",
        "    \"\"\"\n",
        "    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    \n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    # print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
        "            continue\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == \"int\":\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype(\"category\")\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    # print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
        "    # print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "# number of sites\n",
        "n_site = 16"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 123 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l-dqCu9pdaHh"
      },
      "source": [
        "# Training lightGBM\n",
        "### Hyper parameter searching for each location\n",
        "As dataset is huge, we will take 1000000 datapoint and features which we found useful in feature selection phase. For each location and grid search to find best hyper parameters.\n",
        "\n",
        "After hyper parameter search, we will train 16 * 2 models (16 for each site (there are total 16 sites) and 2 cv set for each of 16 models) on the best hyperparameter values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pU4KXbqAdZfx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "fdde3c4ef0cd4d9e985180b377fdbf62",
            "b479f53bc5b5432d8966bb72016cc390",
            "ddd169612a1f4a6e95f7b06012e5a418",
            "07570602500448b989c61de2c453cad6",
            "75e912bdb96640cea1cfb56f75ca5281",
            "2be5f13d45944280a5f9bcfcc7180db3",
            "0e24eb58bcf0461d88021aeb8f19479d",
            "ad6357ab993444f6aa5bd651c04d78a5"
          ]
        },
        "outputId": "4ddc8441-a0c0-4b6e-f362-038055e8d118"
      },
      "source": [
        "# supress userwarning\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# location to store all our outputs\n",
        "folder = \"removed_zero_reading_and_different_hyper_parameter_for_each_location\"\n",
        "\n",
        "# load the unique value list from the disk\n",
        "primary_use_unique_list = load_object(dir_ + \"primary_use_unique_list.pkl\")\n",
        "\n",
        "# load the features which has been selected as a part of feature selection\n",
        "selected_feature_list = [\"meter_reading\"] + list(load_object(dir_ + \"selected_feature_list.pkl\"))\n",
        "\n",
        "# convert non-numeric to numeric\n",
        "le = LabelEncoder()\n",
        "le.fit(primary_use_unique_list)\n",
        "\n",
        "# list of categorical features\n",
        "categorical_features = [\n",
        "    \"building_id\",\n",
        "    \"primary_use\",\n",
        "    \"meter\",\n",
        "    \"weekday\",\n",
        "    \"hour\"]\n",
        "\n",
        "# parameters and corresponding values to search\n",
        "search_parameters = {'num_leaves': (5, 10, 30, 50, 70, 100),\n",
        "                    \"bagging_fraction\": (0.5, 0.8),\n",
        "                    \"feature_fraction\": (0.5, 0.8),\n",
        "                    \"bagging_freq\": (5, 10, 15)}\n",
        "\n",
        "n = 1000000\n",
        "# for each location data\n",
        "for site_id in tqdm(range(n_site)):\n",
        "  \n",
        "  # read the dataframe of current site_id from the disk\n",
        "  train_df = pd.read_feather(dir_+ f\"siteWiseFeatureEngineeredTrainData/site_id_{site_id}/site_id_{site_id}.feather\")\n",
        "\n",
        "  # sample 1000000 points randomly and append it to the daatframe\n",
        "  \n",
        "  if train_df.shape[0] >= n:\n",
        "    train_df = train_df.sample(n=n)\n",
        "\n",
        "  # drop all rows where meter reading is 0\n",
        "  '''\n",
        "  This helped me reduce evaluation loss metric by around 0.1 in both public and private leaderboard\n",
        "  '''\n",
        "  train_df.drop(train_df[train_df.meter_reading == 0].index, axis=\"index\", inplace= True)\n",
        "  \n",
        "  # choose only selected features\n",
        "  train_df = train_df[selected_feature_list].copy(deep= True)\n",
        "\n",
        "  # train features\n",
        "  X = train_df.drop([\"site_id\", \"timestamp\", \"meter_reading\"], axis= \"columns\")\n",
        "  \n",
        "  # convert to numeric\n",
        "  X[\"primary_use\"] = le.transform(X[\"primary_use\"])\n",
        "  \n",
        "  # train lables\n",
        "  y = train_df[\"meter_reading\"].copy(deep= True)\n",
        "\n",
        "  # catboost regressor object\n",
        "  lgb_reg = lgb.LGBMRegressor(learning_rate= 0.05)\n",
        "\n",
        "  # grid search object\n",
        "  grid_search_obj = GridSearchCV(lgb_reg, search_parameters, cv= 2,  return_train_score=True, verbose=0)\n",
        "\n",
        "  # start grid search\n",
        "  grid_search_obj.fit(X, y, categorical_feature= categorical_features)\n",
        "\n",
        "  # save grid search results\n",
        "  save_object(grid_search_obj, dir_ + f\"girdSearchTrainModel/lightgbm/{folder}/grid_search_obj_site_id_{site_id}.pkl\")\n",
        "\n",
        "  # free up memory\n",
        "  free([train_df, grid_search_obj])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdde3c4ef0cd4d9e985180b377fdbf62",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "time: 4h 49min 48s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bReDzRvQv3K2",
        "colab_type": "text"
      },
      "source": [
        "### Training 16 models with 2 fold cross validation\n",
        "Here, we will train lightGBM for each location data with 2 fold cross validation. So we will have 16 * 2 model. To get prediction on query point, we will use model corresponding to site_id as given in the query point and take average of output by both models(we are using 2 models for each site_id as cv set is 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GRTS1oqCtUa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "263e08ce-1120-440c-e9d0-0cd770751ac9"
      },
      "source": [
        "folder = \"removed_zero_reading\"\n",
        "grid_search_obj = load_object(dir_ + f\"girdSearchTrainModel/lightgbm/{folder}/grid_search_obj_site_id_{10}.pkl\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 281 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSfekWU3v1lS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder = \"removed_zero_reading_and_different_hyper_parameter_for_each_location\"\n",
        "'''\n",
        "For each location we perform:\n",
        "  1) Load the data from the disk\n",
        "  2) Select features listed in selected_feature_list\n",
        "  3) Remove redundent features\n",
        "  4) Encode categorical features (If needed)\n",
        "  5) Train the model on best hyper parameter found\n",
        "  6) Save the model into the disk\n",
        "'''\n",
        "\n",
        "# dictionary to hold site_id -> model object mapping\n",
        "models = defaultdict(list)\n",
        "\n",
        "# holds site_id and cv score \n",
        "cv_scores = {\"site_id\": [], \"cv_score\": []}\n",
        "\n",
        "# load the unique value list from the disk\n",
        "primary_use_unique_list = load_object(dir_ + \"primary_use_unique_list.pkl\")\n",
        "\n",
        "# convert non-numeric to numeric\n",
        "le = LabelEncoder()\n",
        "le.fit(primary_use_unique_list)\n",
        "\n",
        "# load the features which has been selected as a part of feature selection\n",
        "selected_feature_list = [\"meter_reading\"] + list(load_object(dir_ + \"selected_feature_list.pkl\"))\n",
        "\n",
        "# number of cv split\n",
        "cv = 2\n",
        "\n",
        "# random state seed\n",
        "seed= 42\n",
        "\n",
        "# for each location data\n",
        "for site_id in tqdm(range(n_site)):\n",
        "  # load grid search object \n",
        "  grid_search_obj = load_object(dir_ + f\"girdSearchTrainModel/lightgbm/{folder}/grid_search_obj_site_id_{site_id}.pkl\")\n",
        "\n",
        "  # get best hyper parameter value\n",
        "  bagging_fraction = grid_search_obj.best_params_[\"bagging_fraction\"]\n",
        "  bagging_freq = grid_search_obj.best_params_[\"bagging_freq\"]\n",
        "  feature_fraction = grid_search_obj.best_params_[\"feature_fraction\"]\n",
        "  num_leaves = grid_search_obj.best_params_[\"num_leaves\"]\n",
        "  \n",
        "  # read the dataframe of current site_id from the disk\n",
        "  train_df = pd.read_feather(dir_+ f\"siteWiseFeatureEngineeredTrainData/site_id_{site_id}/site_id_{site_id}.feather\")\n",
        "  \n",
        "  # drop all rows where meter reading is 0\n",
        "  '''\n",
        "  This helped me reduce evaluation loss metric by around 0.1 in both public and private leaderboard\n",
        "  '''\n",
        "\n",
        "  train_df.drop(train_df[train_df.meter_reading == 0].index, axis=\"index\", inplace= True)\n",
        "  \n",
        "  # choose only selected features\n",
        "  train_df = train_df[selected_feature_list].copy(deep= True)\n",
        "  \n",
        "  free(train_df)\n",
        "  \n",
        "  # free up memory\n",
        "  reduce_mem_usage(train_df)\n",
        "\n",
        "  # list of categorical features\n",
        "  categorical_features = [\n",
        "      \"building_id\",\n",
        "      \"primary_use\",\n",
        "      \"meter\",\n",
        "      \"weekday\",\n",
        "      \"hour\"]\n",
        "\n",
        "\n",
        "  # train features\n",
        "  X = train_df.drop([\"site_id\", \"timestamp\", \"meter_reading\"], axis= \"columns\")\n",
        "  \n",
        "  # convert to numeric\n",
        "  X[\"primary_use\"] = le.transform(X[\"primary_use\"])\n",
        "  \n",
        "  # train lables\n",
        "  y = train_df[\"meter_reading\"].copy(deep= True)\n",
        "\n",
        "  # holds prediction by our model\n",
        "  y_pred_train_site = np.zeros(X.shape[0])\n",
        "\n",
        "  # holds mean RMSE by our current model\n",
        "  score = 0\n",
        "  # original source of  K fold cross validation: https://www.kaggle.com/rohanrao/ashrae-divide-and-conquer\n",
        "\n",
        "  kf = KFold(n_splits=cv, shuffle= True, random_state=seed)\n",
        "  \n",
        "  # for each fold, train model K-1 fold and test it on Kth fold\n",
        "  for fold, (train_index, valid_index) in enumerate(kf.split(X, y)):\n",
        "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
        "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
        "\n",
        "    # lightGBM regressor\n",
        "    lgb_reg = lgb.LGBMRegressor(learning_rate= 0.05,\n",
        "                                bagging_fraction= bagging_fraction,\n",
        "                                bagging_freq= bagging_freq,\n",
        "                                feature_fraction= feature_fraction,\n",
        "                                num_leaves= num_leaves)\n",
        "    # train the model\n",
        "    lgb_reg.fit(X_train, y_train,\n",
        "                eval_set= (X_valid, y_valid),\n",
        "                eval_metric= \"rmse\",\n",
        "                early_stopping_rounds= 25)\n",
        "\n",
        "    # save the model instance in the dict\n",
        "    models[site_id].append(lgb_reg)\n",
        "\n",
        "    y_pred_valid = lgb_reg.predict(X_valid, num_iteration=lgb_reg.best_iteration_)\n",
        "    y_pred_train_site[valid_index] = y_pred_valid\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_valid, y_pred_valid))\n",
        "    print(\"Site Id:\", site_id, \", Fold:\", fold+1, \", RMSE:\", rmse)\n",
        "    score += rmse / cv\n",
        "    \n",
        "    gc.collect()\n",
        "      \n",
        "  cv_scores[\"site_id\"].append(site_id)\n",
        "  cv_scores[\"cv_score\"].append(score)\n",
        "\n",
        "  # free up the memory\n",
        "  free([train_df])\n",
        "\n",
        "  print(\"\\nSite Id:\", site_id, \", CV RMSE:\", np.sqrt(mean_squared_error(y, y_pred_train_site)), \"\\n\")\n",
        "\n",
        "# save the model dict\n",
        "save_object(models, dir_ + f\"models/lightgbm/{folder}/models_dict.pkl\")\n",
        "save_object(cv_scores, dir_ + f\"models/lightgbm/{folder}/cv_scores_dict.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLijXdB8YdYv",
        "colab_type": "text"
      },
      "source": [
        "# Prediction on test data\n",
        "Use the traind model for each site_id and get the prediction for the same"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tckO5E6UYayK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "1adb9390397d4222b5baa18aa0c9131e",
            "cbf071b1abad4bd687f802ea7bfad299",
            "a9888b5091564b3f89c1cd73c9dde07d",
            "fef73b2113fa44ae9d4e9ee6486d7dd4",
            "3975ada082f94b62804a2304f1114841",
            "d276d0e378304970858f3c37b38e7b8d",
            "e6f1cf1eab7c403888553856bb2d6f9f",
            "0a2d255fcb4842a5adbdd275710306c9"
          ]
        },
        "outputId": "23c93984-2dc1-4bd0-97cf-3f5444efa9e1"
      },
      "source": [
        "# load the unique value list from the disk\n",
        "primary_use_unique_list = load_object(dir_ + \"primary_use_unique_list.pkl\")\n",
        "\n",
        "# number of cv split\n",
        "cv = 2\n",
        "\n",
        "# convert non-numeric to numeric\n",
        "le = LabelEncoder()\n",
        "le.fit(primary_use_unique_list)\n",
        "\n",
        "# load the features which has been selected as a part of feature selection\n",
        "selected_feature_list = [\"meter_reading\"] + list(load_object(dir_ + \"selected_feature_list.pkl\"))\n",
        "\n",
        "# load the saved mode dict\n",
        "# models = load_object(dir_ + f\"models/lightgbm/{folder}/models_dict.pkl\")\n",
        "\n",
        "# holds ith prediction by our model\n",
        "# 41697600 is total number of rows in the test data\n",
        "y_pred_test_site = np.zeros(41697600)\n",
        "\n",
        "# list of test years\n",
        "year_list = [2017, 2018]\n",
        "\n",
        "# for each location in test data\n",
        "for site_id in tqdm(range(n_site)):\n",
        "  # for each year\n",
        "  for year in year_list:\n",
        "    # read the dataframe of current site_id from the disk\n",
        "    test_df = pd.read_feather(dir_+ f\"siteWiseFeatureEngineeredTestData/{year}/site_id_{site_id}/site_id_{site_id}.feather\")\n",
        "    test_df.drop([\"site_id\", \"timestamp\"], axis= \"columns\", inplace= True)\n",
        "    \n",
        "    # get model of current location\n",
        "    model = models[site_id]\n",
        "    \n",
        "    # list of row IDs\n",
        "    row_id_list = test_df.pop(\"row_id\")\n",
        "\n",
        "    # free up memory\n",
        "    reduce_mem_usage(test_df)\n",
        "\n",
        "    # convert to numeric representation\n",
        "    test_df[\"primary_use\"] = le.transform(test_df[\"primary_use\"])\n",
        "    \n",
        "    # get predictions by both model\n",
        "    for i in range(cv):\n",
        "      pred = model[i].predict(test_df)/cv\n",
        "      y_pred_test_site[row_id_list] += pred\n",
        "\n",
        "# prepare dataframe for submission\n",
        "df_submit = pd.DataFrame({\"row_id\": range(41697600), \"meter_reading\": y_pred_test_site})\n",
        "\n",
        "# undo log 1 plus operation and clip predictions (make it 0 if prediction is negative)\n",
        "df_submit.meter_reading = np.clip(np.expm1(df_submit.meter_reading), 0, a_max=None)\n",
        "\n",
        "# save the log predictions by our model\n",
        "# save_object(y_pred_test_site, dir_ + \"lightGBM/predictions/y_pred_test_site.pkl\")\n",
        "\n",
        "# df_submit.to_feather(dir_ + \"df_submit.feather\")\n",
        "# df_submit.to_feather(dir_ + f\"models/lightgbm/{folder}/submit.feather\")\n",
        "df_submit.to_csv(dir_ + f\"models/lightgbm/{folder}/submit.csv\", index= False)\n",
        "\n",
        "# flush the stream and unmount the file system\n",
        "unmount()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1adb9390397d4222b5baa18aa0c9131e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "time: 12min 36s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbGXAgAcZ_tn",
        "colab_type": "text"
      },
      "source": [
        "# Experimentation and Results\n",
        "Here is the brief information about experiments and results so far\n",
        "\n",
        "* Initial submission gave us loss metric value of around  **_1.66_** and **1.44**. Here we have used global hyper parameter search (same hyper parameter for all 16 models)\n",
        "<img src= \"https://i.imgur.com/pjfWxbk.png\" height= \"300px\"/>\n",
        "\n",
        "* Removing the 0 value target rows(removing rows where meter_reading is 0 ) helped me to reduce evaluation loss metric by around  **_0.1_** in both public and private leaderboard\n",
        "<img src= \"https://i.imgur.com/MlFUfj6.png\" height= \"300px\"/>\n",
        "\n",
        "* Hyper parameter searching for each location seperatly (16 models with 2 fold cv set) made very little difference, which might not matter at all in real life problems. Here, we get around **_0.01_** loss value improvement at public score board and  **_0.06_** loss value improvement at private score\n",
        "<img src= \"https://i.imgur.com/3divqg4.png\" height= \"300px\"/>\n"
      ]
    }
  ]
}